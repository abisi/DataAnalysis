
%% Guidesheet 4: Principle Component Analysis
clear all;
load('../data/trainSet.mat');
load('../data/trainLabels.mat');

[coeff,score,variance]=pca(trainData);

priorCov=cov(trainData);
postCov=cov(score);
%imshow(postCov);

diagPriorCov=diag(priorCov);
diagPostCov=diag(postCov);

meanPriorVar=mean(diagPriorCov);
%medPriorVar=median(diagPriorCov); %for robustness

meanPostVar=mean(diagPostCov);
%medPostVar=median(diagPostCov);

%Maximum covariance values original data vs transformed data
priorOffDiag=priorCov-diag(diagPriorCov);
maxPriorCov=max(max(priorOffDiag));

postOffDiag=postCov-diag

%PCA maximise the variance in order to get rid off low-variance dimensions.
%Therefore, we observe that the diagonal of the data (before and after
%tranformation), which corresponds to variance, is larger for the
%transformed data (referred as post).
%In terms of informative power, it means that the information content carried by
%the projected data is higher (i.e. lower entropy).

%Diagonal spread along eigenvectors is expressed by the covariance. The
%covariance is minimized in the transformed features. The correlation is
%thus minimised as well, meaning that the features are not correlated and
%carry maximum information. Each PC represent a decrease in the system's
%entropy.

%% PCA and cross-validation



%% Forward Feature Selection
clear all;
load('../data/trainSet.mat');
load('../data/trainLabels.mat');

Priors.ClassNames=[0 1];
Priors.ClassProbs=[0.7 0.3];

classifiertype='diaglinear';
k=10;
ratio=0.5;


selectionCriteria = @(xT,yT,xt,yt) length(yt)*(computeClassError(yt,predict(fitcdiscr(xT,yT,'discrimtype', classifiertype, 'Prior', Priors), xt), ratio));
opt = statset('Display','iter','MaxIter',100);
cp=cvpartition(trainLabels(1:10:end, :),'kfold',k);

[sel,hst] = sequentialfs(selectionCriteria,trainData(1:10:end,:),trainLabels(1:10:end, :),'cv',cp,'options',opt);

%% Nested cross-valiation using FFF instead of rankfeat

clear all;
load('../data/trainSet.mat');
load('../data/trainLabels.mat');

kOut=3;
kIn=10;
partitionOut=cvpartition(length(trainLabels), 'kfold', kOut);

for i=1:kOut
    
end
    






